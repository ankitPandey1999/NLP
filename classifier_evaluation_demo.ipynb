{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "actual_labels = ['spam', 'ham', 'spam', 'spam', 'spam',\n",
    "               'ham', 'ham', 'spam', 'ham', 'spam',\n",
    "               'spam', 'ham', 'ham', 'ham', 'spam',\n",
    "               'ham', 'ham', 'spam', 'spam', 'ham']\n",
    "              \n",
    "predicted_labels = ['spam', 'spam', 'spam', 'ham', 'spam',\n",
    "                    'spam', 'ham', 'ham', 'spam', 'spam',\n",
    "                    'ham', 'ham', 'spam', 'ham', 'ham',\n",
    "                    'ham', 'spam', 'ham', 'spam', 'spam']\n",
    "                    \n",
    "ac = Counter(actual_labels)                     \n",
    "pc = Counter(predicted_labels)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual counts: [('spam', 10), ('ham', 10)]\n"
     ]
    }
   ],
   "source": [
    "print ('Actual counts:', ac.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted counts: [('spam', 11), ('ham', 9)]\n"
     ]
    }
   ],
   "source": [
    "print ('Predicted counts:', pc.most_common())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Predicted:    \n",
      "                   spam ham\n",
      "Actual: spam          5   5\n",
      "        ham           6   4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankit\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: the 'labels' keyword is deprecated, use 'codes' instead\n",
      "  import sys\n",
      "C:\\Users\\ankit\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: the 'labels' keyword is deprecated, use 'codes' instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(y_true=actual_labels,\n",
    "                         y_pred=predicted_labels,\n",
    "                         labels=['spam','ham'])\n",
    "print (pd.DataFrame(data=cm, \n",
    "                   columns=pd.MultiIndex(levels=[['Predicted:'],\n",
    "                                                 ['spam','ham']], \n",
    "                                         labels=[[0,0],[0,1]]), \n",
    "                   index=pd.MultiIndex(levels=[['Actual:'],\n",
    "                                               ['spam','ham']], \n",
    "                                       labels=[[0,0],[0,1]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_class = 'spam'\n",
    "\n",
    "true_positive = 5.\n",
    "false_positive = 6.\n",
    "false_negative = 5.\n",
    "true_negative = 4.\n",
    "\n",
    "accuracy = np.round(\n",
    "                metrics.accuracy_score(y_true=actual_labels,\n",
    "                                       y_pred=predicted_labels),2)\n",
    "accuracy_manual = np.round(\n",
    "                    (true_positive + true_negative) /\n",
    "                      (true_positive + true_negative +\n",
    "                       false_negative + false_positive),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45\n",
      "Manually computed accuracy: 0.45\n"
     ]
    }
   ],
   "source": [
    "print ('Accuracy:', accuracy)\n",
    "print ('Manually computed accuracy:', accuracy_manual)                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.45\n",
      "Manually computed precision: 0.45\n"
     ]
    }
   ],
   "source": [
    "precision = np.round(\n",
    "                metrics.precision_score(y_true=actual_labels,\n",
    "                                        y_pred=predicted_labels,\n",
    "                                        pos_label=positive_class),2)\n",
    "precision_manual = np.round(\n",
    "                        (true_positive) /\n",
    "                        (true_positive + false_positive),2)\n",
    "print ('Precision:', precision)\n",
    "print ('Manually computed precision:', precision_manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.5\n",
      "Manually computed recall: 0.5\n"
     ]
    }
   ],
   "source": [
    "recall = np.round(\n",
    "            metrics.recall_score(y_true=actual_labels,\n",
    "                                 y_pred=predicted_labels,\n",
    "                                 pos_label=positive_class),2)\n",
    "recall_manual = np.round(\n",
    "                    (true_positive) /\n",
    "                    (true_positive + false_negative),2)\n",
    "print ('Recall:', recall)\n",
    "print ('Manually computed recall:', recall_manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.48\n",
      "Manually computed F1 score: 0.47\n"
     ]
    }
   ],
   "source": [
    "f1_score = np.round(\n",
    "                metrics.f1_score(y_true=actual_labels,\n",
    "                                 y_pred=predicted_labels,\n",
    "                                 pos_label=positive_class),2) \n",
    "f1_score_manual = np.round(\n",
    "                    (2 * precision * recall) /\n",
    "                    (precision + recall),2)\n",
    "print ('F1 score:', f1_score)\n",
    "print ('Manually computed F1 score:', f1_score_manual)                                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
