{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS Taggers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DET'), ('brown', 'ADJ'), ('fox', 'NOUN'), ('is', 'VERB'), ('quick', 'ADJ'), ('and', 'CONJ'), ('he', 'PRON'), ('is', 'VERB'), ('jumping', 'VERB'), ('over', 'ADP'), ('the', 'DET'), ('lazy', 'ADJ'), ('dog', 'NOUN')]\n"
     ]
    }
   ],
   "source": [
    "sentence = 'The brown fox is quick and he is jumping over the lazy dog'\n",
    "\n",
    "\n",
    "# recommended tagger based on PTB\n",
    "import nltk\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "tagged_sent = nltk.pos_tag(tokens, tagset='universal')\n",
    "print (tagged_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('brown', 'JJ'), ('fox', 'NN'), ('is', 'VBZ'), ('quick', 'JJ'), ('and', 'CC'), ('he', 'PRP'), ('is', 'VBZ'), ('jumping', 'VBG'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "from pattern.en import tag \n",
    "\n",
    "tagged_sent = tag(sentence)\n",
    "print (tagged_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " That output gives us tags that purely follow the Penn Treebank format, specifying the\n",
    "form of adjective, noun, or verb in more detail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n",
      "0.1454158195372253\n",
      "[('The', 'NN'), ('brown', 'NN'), ('fox', 'NN'), ('is', 'NN'), ('quick', 'NN'), ('and', 'NN'), ('he', 'NN'), ('is', 'NN'), ('jumping', 'NN'), ('over', 'NN'), ('the', 'NN'), ('lazy', 'NN'), ('dog', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# building your own tagger\n",
    "\n",
    "# preparing the data\n",
    "from nltk.corpus import treebank\n",
    "data = treebank.tagged_sents()\n",
    "train_data = data[:3500]\n",
    "test_data = data[3500:]\n",
    "print (train_data[0])\n",
    "\n",
    "# default tagger\n",
    "from nltk.tag import DefaultTagger\n",
    "dt = DefaultTagger('NN')\n",
    "\n",
    "print (dt.evaluate(test_data))\n",
    "\n",
    "print (dt.tag(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the preceding output we have obtained 14 percent accuracy in\n",
    "correctly tagging words from the treebank test dataset—which is not that great, and the\n",
    "output tags on our sample sentence are all nouns, just as we expected because we fed the\n",
    "tagger with the same tag.\n",
    " We will now use regular expressions and the RegexpTagger to see if we can build a\n",
    "better performing tagger : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24039113176493368\n",
      "[('The', 'NN'), ('brown', 'NN'), ('fox', 'NN'), ('is', 'NNS'), ('quick', 'NN'), ('and', 'NN'), ('he', 'NN'), ('is', 'NNS'), ('jumping', 'VBG'), ('over', 'NN'), ('the', 'NN'), ('lazy', 'NN'), ('dog', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# regex tagger\n",
    "from nltk.tag import RegexpTagger\n",
    "# define regex tag patterns\n",
    "patterns = [\n",
    "        (r'.*ing$', 'VBG'),               # gerunds\n",
    "        (r'.*ed$', 'VBD'),                # simple past\n",
    "        (r'.*es$', 'VBZ'),                # 3rd singular present\n",
    "        (r'.*ould$', 'MD'),               # modals\n",
    "        (r'.*\\'s$', 'NN$'),               # possessive nouns\n",
    "        (r'.*s$', 'NNS'),                 # plural nouns\n",
    "        (r'^-?[0-9]+(.[0-9]+)?$', 'CD'),  # cardinal numbers\n",
    "        (r'.*', 'NN')                     # nouns (default) ... \n",
    "]\n",
    "rt = RegexpTagger(patterns)\n",
    "\n",
    "print (rt.evaluate(test_data))\n",
    "print (rt.tag(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That output shows that the accuracy has now increased to 24 percent. But can we do\n",
    "better? We will now train some n-gram taggers. n-grams are contiguous sequences of n\n",
    "items from a sequence of text or speech. These items could consist of words, phonemes,\n",
    "letters, characters, or syllables. Shingles are n-grams where the items only consist of\n",
    "words. We will use n-grams of size 1, 2, and 3, which are also known as unigram , bigram ,\n",
    "and trigram respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8607803272340013\n",
      "[('The', 'DT'), ('brown', None), ('fox', None), ('is', 'VBZ'), ('quick', 'JJ'), ('and', 'CC'), ('he', 'PRP'), ('is', 'VBZ'), ('jumping', 'VBG'), ('over', 'IN'), ('the', 'DT'), ('lazy', None), ('dog', None)]\n",
      "0.13466937748087907\n",
      "[('The', 'DT'), ('brown', None), ('fox', None), ('is', None), ('quick', None), ('and', None), ('he', None), ('is', None), ('jumping', None), ('over', None), ('the', None), ('lazy', None), ('dog', None)]\n",
      "0.08064672281924679\n",
      "[('The', 'DT'), ('brown', None), ('fox', None), ('is', None), ('quick', None), ('and', None), ('he', None), ('is', None), ('jumping', None), ('over', None), ('the', None), ('lazy', None), ('dog', None)]\n"
     ]
    }
   ],
   "source": [
    "## N gram taggers\n",
    "from nltk.tag import UnigramTagger\n",
    "from nltk.tag import BigramTagger\n",
    "from nltk.tag import TrigramTagger\n",
    "\n",
    "ut = UnigramTagger(train_data)\n",
    "bt = BigramTagger(train_data)\n",
    "tt = TrigramTagger(train_data)\n",
    "\n",
    "print (ut.evaluate(test_data))\n",
    "print (ut.tag(tokens))\n",
    "\n",
    "print (bt.evaluate(test_data))\n",
    "print (bt.tag(tokens))\n",
    "\n",
    "print (tt.evaluate(test_data))\n",
    "print (tt.tag(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The preceding output clearly shows that we obtain 86 percent accuracy on the test\n",
    "set using UnigramTagger tagger alone, which is really good compared to our last tagger.\n",
    "The None tag indicates the tagger was unable to tag that word, the reason being that it was\n",
    "unable to get a similar token in the training data. Accuracies of the bigram and trigram\n",
    "models are far less because it is not always the case that the same bigrams and trigrams it\n",
    "had observed in the training data will also be present in the same way in the testing data.\n",
    " We will now look at an approach to combine all the taggers by creating a combined\n",
    "tagger with a list of taggers and use a backoff tagger. Essentially we would create a chain of\n",
    "taggers, and each tagger would fall back on a backoff tagger if it cannot tag the input tokens : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9094781682641108\n",
      "[('The', 'DT'), ('brown', 'NN'), ('fox', 'NN'), ('is', 'VBZ'), ('quick', 'JJ'), ('and', 'CC'), ('he', 'PRP'), ('is', 'VBZ'), ('jumping', 'VBG'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'NN'), ('dog', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "def combined_tagger(train_data, taggers, backoff=None):\n",
    "    for tagger in taggers:\n",
    "        backoff = tagger(train_data, backoff=backoff)\n",
    "    return backoff\n",
    "\n",
    "ct = combined_tagger(train_data=train_data, \n",
    "                     taggers=[UnigramTagger, BigramTagger, TrigramTagger],\n",
    "                     backoff=rt)\n",
    "\n",
    "print (ct.evaluate(test_data))        \n",
    "print (ct.tag(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We now obtain an accuracy of 91 percent on the test data, which is excellent. Also we\n",
    "see that this new tagger is able to successfully tag all the tokens in our sample sentence\n",
    "(even though a couple of them are not correct, like brown should be an adjective). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9306806079969019\n",
      "[('The', 'DT'), ('brown', 'JJ'), ('fox', 'NN'), ('is', 'VBZ'), ('quick', 'JJ'), ('and', 'CC'), ('he', 'PRP'), ('is', 'VBZ'), ('jumping', 'VBG'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'VBG')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import NaiveBayesClassifier, MaxentClassifier\n",
    "from nltk.tag.sequential import ClassifierBasedPOSTagger\n",
    "\n",
    "nbt = ClassifierBasedPOSTagger(train=train_data,\n",
    "                               classifier_builder=NaiveBayesClassifier.train)\n",
    "\n",
    "print (nbt.evaluate(test_data))\n",
    "print (nbt.tag(tokens))    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the preceding tagger , we get an accuracy of 93 percent on our test data—the\n",
    "highest out of all our taggers. Also if you observe the output tags for our sample sentence,\n",
    "you will see they are correct and make perfect sense. This gives us an idea of how\n",
    "powerful and effective classifier-based POS taggers can be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -3.82864        0.007\n",
      "             2          -0.76176        0.957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankit\\Anaconda3\\lib\\site-packages\\nltk\\classify\\maxent.py:1392: RuntimeWarning: overflow encountered in power\n",
      "  exp_nf_delta = 2 ** nf_delta\n",
      "C:\\Users\\ankit\\Anaconda3\\lib\\site-packages\\nltk\\classify\\maxent.py:1394: RuntimeWarning: invalid value encountered in multiply\n",
      "  sum1 = numpy.sum(exp_nf_delta * A, axis=0)\n",
      "C:\\Users\\ankit\\Anaconda3\\lib\\site-packages\\nltk\\classify\\maxent.py:1395: RuntimeWarning: invalid value encountered in multiply\n",
      "  sum2 = numpy.sum(nf_exp_nf_delta * A, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Final               nan        0.984\n",
      "0.9270016458514861\n"
     ]
    }
   ],
   "source": [
    "# Using MaxentClassifier\n",
    "met = ClassifierBasedPOSTagger(train=train_data,\n",
    "                               classifier_builder=MaxentClassifier.train)\n",
    "print (met.evaluate(test_data))                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('brown', 'NN'), ('fox', 'NN'), ('is', 'VBZ'), ('quick', 'JJ'), ('and', 'CC'), ('he', 'PRP'), ('is', 'VBZ'), ('jumping', 'VBG'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'NN'), ('dog', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "print (met.tag(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
